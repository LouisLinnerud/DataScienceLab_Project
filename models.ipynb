{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "Trying out different models and paramaters to see which performs the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the evaluation data\n",
    "dev = pd.read_csv(\"../csv_files/development.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the positions and removes the x and y column.\n",
    "import numpy as np\n",
    "pos_dev = dev[[\"x\", \"y\"]]\n",
    "\n",
    "## Dropping data from x and y \n",
    "dev = dev.drop([\"x\", \"y\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing pads with format: pads = [0, 7, 12, ..]\n",
    "def drop_pads(input_list, df):\n",
    "    for i in input_list:\n",
    "        columns_to_remove = df.filter(like=f'[{i}]').columns\n",
    "        df = df.drop(columns=columns_to_remove)\n",
    "    return df\n",
    "\n",
    "remove_pads = [0, 7, 12, 15, 16, 17]\n",
    "dev_removed_noise = drop_pads(remove_pads, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing rms feature\n",
    "def drop_rms_features(df):\n",
    "    # Extract columns that start with 'rms'\n",
    "    rms_columns = [col for col in df.columns if not col.startswith('rms')]\n",
    "\n",
    "    # Create a new DataFrame without 'rms' columns\n",
    "    df_without_rms = df[rms_columns] \n",
    "    return df_without_rms\n",
    "\n",
    "dev_interesting_data = drop_rms_features(dev_removed_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Z-transformation of the data. Remember to scale accordingly to training data for eval data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(dev_interesting_data)\n",
    " \n",
    "dev_interesting_data = pd.DataFrame(scaler.transform(dev_interesting_data), columns=dev_interesting_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Reducing the dataset to X percent of original size to speed up model testing\n",
    "# dev_interesting_data_sample = dev_interesting_data.sample(frac=0.25)\n",
    "# pos_dev_sample = pos_dev.loc[dev_interesting_data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting into train and validation set\n",
    "X_train, X_val, pos_train, pos_val = train_test_split(dev_interesting_data, pos_dev, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import math\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "numb_trees = 35\n",
    "base_regressor = RandomForestRegressor(n_estimators=numb_trees, criterion=\"poisson\", max_depth=30, max_features=0.3, bootstrap=True) \n",
    "mult_regr = MultiOutputRegressor(base_regressor)\n",
    "\n",
    "mult_regr.fit(X_train, pos_train)\n",
    "\n",
    "pos_pred = mult_regr.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on GridSearchCV\n",
    "By splitting the problem into a regression problem for x-coordinate and y-coordinate I used GridSearchCV with these paramaters:\n",
    "   \n",
    "    param_grid = {  \n",
    "        'max_depth': [20, 30, 40],  # Maximum depth of the tree\n",
    "        'min_samples_split':[2, 4, 6], # Minimum number of samples required to split an internal node\n",
    "        'min_samples_leaf': [1, 2, 4], # Minimum number of samples required to be at a leaf node\n",
    "        'max_features': [\"sqrt\", \"log2\", None]\n",
    "        }  \n",
    "         \n",
    "The best paramaters for x-coordinate and y-coordinate were: \n",
    "  \n",
    "{'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}  \n",
    "{'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 4}  \n",
    "\n",
    " \n",
    " This GridSearch is run on only 1% of the dataset in order to speed up the process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error = 2.85\n",
      "Mean squared error = 14.59\n",
      "Median absolute error = 2.29\n",
      "Explain variance score = 1.0\n",
      "R2 score = 1.0\n",
      "Mean eucledian distance = 4.5\n"
     ]
    }
   ],
   "source": [
    "# Metrics to evaluating model \n",
    "import sklearn.metrics as sm\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def avg_euc_dist(pos_val, pos_pred):\n",
    "    sum_square = 0\n",
    "    for i in range(len(pos_val)):\n",
    "        sum_square += math.sqrt((pos_val[i][0]-pos_pred[i][0])**2 + (pos_val[i][1]-pos_pred[i][1])**2)\n",
    "    return sum_square/len(pos_val)    \n",
    "\n",
    "def metrics_on_model(pos_val, pos_pred):\n",
    "    print(\"Mean absolute error =\", round(sm.mean_absolute_error(pos_val, pos_pred), 2)) \n",
    "    print(\"Mean squared error =\", round(sm.mean_squared_error(pos_val, pos_pred), 2)) \n",
    "    print(\"Median absolute error =\", round(sm.median_absolute_error(pos_val, pos_pred), 2)) \n",
    "    print(\"Explain variance score =\", round(sm.explained_variance_score(pos_val, pos_pred), 2)) \n",
    "    print(\"R2 score =\", round(sm.r2_score(pos_val, pos_pred), 2))\n",
    "    print(\"Mean eucledian distance =\", round(avg_euc_dist(pos_val, pos_pred), 2))\n",
    "\n",
    "metrics_on_model(pos_val.to_numpy(), pos_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:\n",
    "\n",
    "Test 1:  \n",
    "    Data: reomving pads (0, 7, 12, 15, 16, 17)  \n",
    "    Number of trees: 10   \n",
    "    Mean euc dist: 5.77  \n",
    "\n",
    "Test 2:  \n",
    "    Data: reomving pads (0, 7, 12, 15, 16, 17) and removing rms feature  \n",
    "    Number of trees: 10  \n",
    "    Mean euc dist: 5.69\n",
    "\n",
    "Test 3:    \n",
    "    Data: Sampeled 25% of the data to speed up model training. Reomving pads (0, 7, 12, 15, 16, 17) and removing rms feature.  \n",
    "    Number of trees: 10  \n",
    "    Mean euc dist: 6.56  \n",
    "\n",
    "Test 4:    \n",
    "    Data: Sampeled 25% of the data to speed up model training. Reomving pads (0, 7, 12, 15, 16, 17) and removing rms feature.  \n",
    "    Number of trees: 30  \n",
    "    Mean euc dist: 6.16  \n",
    "\n",
    "Test 4:    \n",
    "    Data: With PCA. Sampeled 25% of the data to speed up model training. Reomving pads (0, 7, 12, 15, 16, 17) and removing rms feature.  \n",
    "    Number of trees: 30  \n",
    "    Mean euc dist: 10.29\n",
    "\n",
    "Test 5:        \n",
    "    Data: Reomving pads (0, 7, 12, 15, 16, 17) and removing rms feature. Added RobustScaling.   \n",
    "    Number of trees: 50  \n",
    "    Mean euc dist: 5.31  \n",
    "\n",
    "Test 6:  \n",
    "    Data: Reomving pads (0, 7, 12, 15, 16, 17) and removing rms feature. Added column: pmax[5]*area[5] \n",
    "    Number of trees: 30  \n",
    "    Mean euc dist: 6.11\n",
    "\n",
    "Test 7:   \n",
    "    Data: Reomving pads (0, 7, 12, 15, 16, 17) and removing rms feature.  \n",
    "    Number of trees: 25  \n",
    "    Mean euc dist: 6.58  \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the multiple_reg_model on the evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_data = pd.read_csv(\"../csv_files/evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the ID\n",
    "eval_id = ev_data[\"Id\"]\n",
    "\n",
    "# Dropping the Id column from the ev_data\n",
    "ev_data = ev_data.drop([\"Id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting the position array to a string to be used in the .csv file \n",
    "def pred_to_string(prediction_array):\n",
    "    pred_column = []\n",
    "    for i in range(len(prediction_array)):\n",
    "        pos_string = (str(prediction_array[i][0]) + \"|\" + str(prediction_array[i][1]))\n",
    "        pred_column.append(pos_string)\n",
    "    return pred_column\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing \n",
    "remove_pads = [0, 7, 12, 15, 16, 17]\n",
    "ev_data = drop_pads(remove_pads, ev_data) # Remove pads\n",
    "ev_data = drop_rms_features(ev_data) # Remove rms feature \n",
    "ev_data = pd.DataFrame(scaler.transform(ev_data), columns=ev_data.columns) # Z-transform with mean and std from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the evaluation results\n",
    "mult_regr_eval = mult_regr.predict(ev_data)\n",
    "pos_pred = pred_to_string(mult_regr_eval) # Formatting the predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df and .csv file to be submitted. Saved in submission_file folder\n",
    "mult_reg_submission = pd.DataFrame({'Id': eval_id, 'Predicted': pos_pred})\n",
    "mult_reg_submission.to_csv(\"../DataScienceLab_Project/submission_files/mult_reg_rand_forest_tuned_hyperparam_z_score_correct_pads.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
